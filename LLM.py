"""
LLM.py - Gemini ê¸°ë°˜ ëŒ€í™” ìƒì„± ëª¨ë“ˆ
"""
import logging
import os
from typing import Optional, List, Dict
import google.generativeai as genai

logging.basicConfig(level=logging.INFO, format='%(asctime)s [LLM] %(message)s')
logger = logging.getLogger(__name__)

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ 'í•˜ì´'ë¼ëŠ” ì´ë¦„ì˜ AI ê±´ê°• ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
76ì„¸ ë…ê±° ì–´ë¥´ì‹ ê³¼ ì „í™” í†µí™”ë¥¼ í•˜ê³  ìˆìŠµë‹ˆë‹¤.

## ë§íˆ¬ ê·œì¹™
- ë”°ëœ»í•˜ê³  ì¹œê·¼í•œ ì†ë…€ ê°™ì€ ë§íˆ¬ë¡œ ëŒ€í™”í•˜ì„¸ìš”
- ë¬¸ì¥ì€ ì§§ê³  ëª…í™•í•˜ê²Œ (2-3ë¬¸ì¥ ì´ë‚´)
- ë†’ì„ë§ì„ ì‚¬ìš©í•˜ë˜ ë”±ë”±í•˜ì§€ ì•Šê²Œ
- ì ì ˆí•œ ê³µê°ê³¼ ì¹­ì°¬ì„ í‘œí˜„í•˜ì„¸ìš”

## ëŒ€í™” ëª©í‘œ
1. ì•ˆë¶€ í™•ì¸ (ê¸°ë¶„, ê±´ê°• ìƒíƒœ)
2. ì‹ì‚¬ ì—¬ë¶€ í™•ì¸
3. ì•½ ë³µìš© ì—¬ë¶€ í™•ì¸
4. ì¼ìƒ ëŒ€í™”ë¡œ ì™¸ë¡œì›€ í•´ì†Œ

## ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­ (ë§¤ìš° ì¤‘ìš”)
- ì´ëª¨í‹°ì½˜, ì´ëª¨ì§€ ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ (ğŸ˜Šâ¤ï¸ ë“± ëª¨ë“  íŠ¹ìˆ˜ë¬¸ì ì´ëª¨í‹°ì½˜ ê¸ˆì§€)
- ì˜ë£Œ ì§„ë‹¨ì´ë‚˜ ì²˜ë°© ê¸ˆì§€
- í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•˜ì„¸ìš”

## ê¸°íƒ€ ì£¼ì˜ì‚¬í•­
- ì‘ê¸‰ ìƒí™© ì‹œ 119 ì•ˆë‚´
- í•­ìƒ ê¸ì •ì ì´ê³  ë”°ëœ»í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”

ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•´ì£¼ì„¸ìš”. ë‹¤ì‹œ í•œë²ˆ ê°•ì¡°: ì´ëª¨í‹°ì½˜/ì´ëª¨ì§€ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."""


class LLM:
    """Gemini ëŒ€í™” ìƒì„±"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        Args:
            api_key: Google API í‚¤
        """
        self.api_key = api_key or os.getenv("GOOGLE_API_KEY")
        
        if not self.api_key:
            logger.error("GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            self.model = None
            self.chat = None
            return
        
        try:
            genai.configure(api_key=self.api_key)
            
            self.model = genai.GenerativeModel(
                model_name="gemini-2.5-flash-lite",  # ë¬´ë£Œ í‹°ì–´ì—ì„œ ê°€ì¥ ì•ˆì •ì 
                system_instruction=SYSTEM_PROMPT,
                generation_config={
                    "temperature": 0.8,
                    "max_output_tokens": 150,
                    "top_p": 0.9,
                }
            )
            
            self.chat = self.model.start_chat(history=[])
            self.history: List[Dict] = []
            
            logger.info("LLM ì´ˆê¸°í™” ì™„ë£Œ (Gemini)")
            
        except Exception as e:
            logger.error(f"LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.model = None
            self.chat = None
    
    def generate(self, user_input: str) -> str:
        """
        ì‘ë‹µ ìƒì„± (ë™ê¸°)
        
        Args:
            user_input: ì‚¬ìš©ì ì…ë ¥ í…ìŠ¤íŠ¸
            
        Returns:
            AI ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        if not user_input or not user_input.strip():
            return ""
        
        if not self.chat:
            logger.warning("LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë°ëª¨ ì‘ë‹µ ì‚¬ìš©")
            return self._demo_response(user_input)
        
        try:
            logger.info(f"ì…ë ¥: {user_input}")
            
            response = self.chat.send_message(user_input)
            ai_response = response.text.strip()
            
            # íˆìŠ¤í† ë¦¬ ì €ì¥
            self.history.append({"role": "user", "content": user_input})
            self.history.append({"role": "ai", "content": ai_response})
            
            logger.info(f"ì‘ë‹µ: {ai_response}")
            return ai_response
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            # 429 ì¿¼í„° ì´ˆê³¼ ì‹œ ë°ëª¨ ì‘ë‹µìœ¼ë¡œ í´ë°±
            if "429" in str(e) or "quota" in str(e).lower():
                logger.warning("API ì¿¼í„° ì´ˆê³¼ - ë°ëª¨ ëª¨ë“œë¡œ ì „í™˜")
                return self._demo_response(user_input)
            return "ì£„ì†¡í•´ìš” í• ë¨¸ë‹ˆ, ì˜ ëª» ë“¤ì—ˆì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
    
    async def generate_async(self, user_input: str) -> str:
        """ë¹„ë™ê¸° ì‘ë‹µ ìƒì„±"""
        if not user_input or not user_input.strip():
            return ""
        
        if not self.chat:
            return self._demo_response(user_input)
        
        try:
            logger.info(f"ì…ë ¥: {user_input}")
            
            response = await self.chat.send_message_async(user_input)
            ai_response = response.text.strip()
            
            self.history.append({"role": "user", "content": user_input})
            self.history.append({"role": "ai", "content": ai_response})
            
            logger.info(f"ì‘ë‹µ: {ai_response}")
            return ai_response
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}")
            # 429 ì¿¼í„° ì´ˆê³¼ ì‹œ ë°ëª¨ ì‘ë‹µìœ¼ë¡œ í´ë°±
            if "429" in str(e) or "quota" in str(e).lower():
                logger.warning("API ì¿¼í„° ì´ˆê³¼ - ë°ëª¨ ëª¨ë“œë¡œ ì „í™˜")
                return self._demo_response(user_input)
            return "ì£„ì†¡í•´ìš”, ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì‹œê² ì–´ìš”?"
    
    def _demo_response(self, text: str) -> str:
        """ë°ëª¨ ì‘ë‹µ (API ì—†ì„ ë•Œ)"""
        responses = {
            "ì•ˆë…•": "ì•ˆë…•í•˜ì„¸ìš” í• ë¨¸ë‹ˆ~ ì˜¤ëŠ˜ ê¸°ë¶„ì´ ì–´ë– ì„¸ìš”?",
            "ì•½": "ì•½ ë“œì…¨ì–´ìš”? ê±´ê°•ì„ ìœ„í•´ ê¼­ ì±™ê²¨ ë“œì„¸ìš”~",
            "ë°¥": "ë°¥ ë§›ìˆê²Œ ë“œì…¨êµ°ìš”! ë­ ë“œì…¨ì–´ìš”?",
            "ì•„íŒŒ": "ì–´ë¨¸, ì–´ë””ê°€ ë¶ˆí¸í•˜ì„¸ìš”? ë§ì´ ì•„í”„ì‹œë©´ ë³‘ì›ì— ê°€ë³´ì…”ì•¼ í•´ìš”.",
            "ì‹¬ì‹¬": "ì‹¬ì‹¬í•˜ì‹œë©´ ì €ë‘ ì´ì•¼ê¸°í•´ìš”! ìš”ì¦˜ ë­ í•˜ê³  ì§€ë‚´ì„¸ìš”?",
            "ê³ ë§ˆ": "í• ë¨¸ë‹ˆê°€ ê±´ê°•í•˜ê²Œ ì§€ë‚´ì‹œëŠ” ê²Œ ì €í•œí…ŒëŠ” ê°€ì¥ í° ì„ ë¬¼ì´ì—ìš”~",
            "ë¨¹": "ë§›ìˆê²Œ ë“œì…¨ì–´ìš”? ì˜ ë“œì…”ì•¼ í˜ì´ ë‚˜ìš”~",
        }
        
        for keyword, response in responses.items():
            if keyword in text:
                return response
        
        return "ë„¤ í• ë¨¸ë‹ˆ, ë” ë§ì”€í•´ ì£¼ì„¸ìš”~"
    
    def get_greeting(self) -> str:
        """ì¸ì‚¬ë§"""
        return "í• ë¨¸ë‹ˆ~ ì € í•˜ì´ì˜ˆìš”! ì ì‹¬ ë§›ìˆê²Œ ë“œì…¨ì–´ìš”?"
    
    def reset(self):
        """ëŒ€í™” ì´ˆê¸°í™”"""
        if self.model:
            self.chat = self.model.start_chat(history=[])
        self.history.clear()
        logger.info("ëŒ€í™” ì´ˆê¸°í™”ë¨")


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    
    llm = LLM()
    if llm.chat:
        response = llm.generate("ì•ˆë…•í•˜ì„¸ìš”")
        print(f"ì‘ë‹µ: {response}")
    else:
        print("LLM ì´ˆê¸°í™” ì‹¤íŒ¨")